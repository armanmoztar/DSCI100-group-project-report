{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Half-Time Statistics to Predict the Outcome of a Soccer Game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSCI 100 - 005, GROUP 03, CARLOS PEREZ, ABBEY DORIS, ARMAN MOZTARZADEH, DARREN LIU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betting on the outcome of sports matches has become very popular in the sporting community, making up roughly 30 to 40 percent of the global gambling market (“Most Popular Sports to Bet On”, 2022). Additionally, it is estimated that a total of over $700 million is put into bets annually, with some of the largest unions having hundreds of thousands of customers from all around the world alongside AI-powered algorithms. It is predicted that approximately 7 billion dollars will be generated in revenue by 2025, from only 833 million dollars in 2019 in just the United States alone. Unfortunately, inaccurate assessment of data will more than likely result in incorrect outcomes, which would surely wash lots of money down the drain. With its growing popularity comes the increasing need to be accurate when casting one’s bet on a game, especially when an AI is involved, as a multitude of factors must all be considered, raising issues of reliability. In today’s world, “highly complex computer systems offer a more comprehensive insight into a football match’s data. The numbers and statistics gained lead to a large volume of new sorts of information about the match.” (Horkey et al., 2016). To address these issues, we created a tool using regression to accurately and reliably predict the outcome of sports games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the issue outlined previously, we will be creating a regression model to answer the question “How do current match plays and statistics influence the outcome of a soccer game and how can one predict the outcome of a soccer game using match plays/statistics and current betting odds to accurately predict how much the winning team will win by.” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our analysis, we gathered our quantitative data from datahub.io (https://datahub.io/sports-data/english-premier-league#resource-season-1819) which stores centralized sports data from various premier league seasons. We decided to focus our report on the most recent season that the database contained, (2018 season). Since our report was focused on betting on the outcome of a match, we chose to only incorporate the variables that were pertinent to our dataset. As a result, variables such as FTR (Full Time Result) and Referee were dropped, as we collectively agreed that they were completely unrelated to our goal, while other more relevant ones, such as HTAG (Half Time Away Team Goals). Despite our dataset containing the relevant information we needed to make our prediction, we chose to further manipulate and create a new variable to add more depth and context to our report. This new variable was the value of NetScore, which allowed us to incorporate the final predictions into a single variable instead of performing regression twice on two different variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also various betting websites in which people can bet on soccer games. These betting websites also release the “betting odds” to the public as statistics which were incorporated into our prediction variables to maximise precision and accuracy in our betting odds. By studying what other people were betting, we were able to use how the general public perceived the chances of a certain team winning into our own regression model. This allowed us to have our regression model be influenced by current match statistics and the public perception. The public perception can give insight that current match statistics can’t, like if a key player is going to be substituted on or off later on in the match. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, various libraries were loaded into R to have access to the functions used in the regression (repr, tidyverse, tidymodels, digest, GGally, ISLR). Then the data was loaded from a url and mutated into the data types that were best to work with. Next, we took our match data and used an “initial_split” function to split the data into 25% testing data and 75% training data using “FTR” as a strata. This meant that the testing and training data had an equal proportion of games where the home team won, lost or tied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we created a new variable column that combined the scores of the home team and the away team into a column called “NetScore”. The value of “NetScore” represented the difference in score between the home and away team, with a positive “NetScore” meaning that the home team won and a negative value representing the away team winning. The tibbles are presented in the code for a clear picture of what each value represents in a match context. Next we provide a summary of the data representing which soccer teams won the most amount of games at home and away.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next, we work on creating two regression models, using the KNN algorithm and linear algorithm. We do both so we can compare which model gives the lowest RMPSE which will signal which model performs the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the KNN regression model, 3 sub recipes are created in order to compare which predictor variables give the lowest RMSE value. Next we perform a 5-fold cross-validation on the training data so that we remove variations due to random data selection. Then each individual recipe is worked into the corresponding workflow. Then we create a tibble in order to test possible values of k ranging from 1 to 200. Then we used the “collect_metrics'' function to receive numerical estimates of the mean RMSE value to choose the best possible combination of variables. Using the k value given by the best variable recipe, we fit the workflow to the training recipe and test it with the testing to each the RMPSE of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize the analysis of our data using “ggplot” and “geom_histogram. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the linear regression model using the “linear_reg” function. We use the recipe we determined was best to create the linear regression workflow. Then we fit the model to the training data using the “fit” function and finalize the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to determine whether linear or KNN regression was better, we create two histograms side by side, with the error distribution as the x axis and the count as the y axis. This allows us to see what model has a peak at optimum value and determine which model gives the more accurate prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "“package ‘tidymodels’ was built under R version 4.0.2”\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 0.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom    \u001b[39m 0.7.0      \u001b[32m✔\u001b[39m \u001b[34mrecipes  \u001b[39m 0.1.13\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials    \u001b[39m 0.0.9      \u001b[32m✔\u001b[39m \u001b[34mrsample  \u001b[39m 0.0.7 \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer    \u001b[39m 0.5.4      \u001b[32m✔\u001b[39m \u001b[34mtune     \u001b[39m 0.1.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata\u001b[39m 0.0.2      \u001b[32m✔\u001b[39m \u001b[34mworkflows\u001b[39m 0.2.0 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip  \u001b[39m 0.1.3      \u001b[32m✔\u001b[39m \u001b[34myardstick\u001b[39m 0.0.7 \n",
      "\n",
      "Warning message:\n",
      "“package ‘broom’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dials’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘infer’ was built under R version 4.0.3”\n",
      "Warning message:\n",
      "“package ‘modeldata’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘parsnip’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘recipes’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tune’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘workflows’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘yardstick’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\n",
      "Registered S3 method overwritten by 'GGally':\n",
      "  method from   \n",
      "  +.gg   ggplot2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(repr)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "library(digest)\n",
    "library(GGally)\n",
    "library(ISLR)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "set.seed(7493)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are reading the data. From a URL and changing the values of the AwayTeam and HomeTeam as factors to create distinct teams. Next, the results to be predicted, FTHG and FTAG are also changed to integer values instead of decimals because the number of goals scored in a soccer game is always an integer value. FTHG = full time home goals. FTAG = full time away goals. We also change FTR (full time results) to factors so the data can be split evenly. FTR is also a value to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double(),\n",
      "  Div = \u001b[31mcol_character()\u001b[39m,\n",
      "  Date = \u001b[31mcol_character()\u001b[39m,\n",
      "  HomeTeam = \u001b[31mcol_character()\u001b[39m,\n",
      "  AwayTeam = \u001b[31mcol_character()\u001b[39m,\n",
      "  FTR = \u001b[31mcol_character()\u001b[39m,\n",
      "  HTR = \u001b[31mcol_character()\u001b[39m,\n",
      "  Referee = \u001b[31mcol_character()\u001b[39m\n",
      ")\n",
      "\n",
      "See spec(...) for full column specifications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url <- \"https://raw.githubusercontent.com/armanmoztar/group-project/main/data/season_2018.csv\"\n",
    "\n",
    "match_data <- read_csv(url) %>%    #reading the csv from url\n",
    "            mutate(FTR = as_factor(FTR),       # mutate changes the data in the types we want\n",
    "                  AwayTeam = as_factor(AwayTeam),\n",
    "                  FTHG = as.integer(FTHG),\n",
    "                  FTAG = as.integer(FTAG),\n",
    "                  HomeTeam = as_factor(HomeTeam))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A spec_tbl_df: 380 × 62</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Div</th><th scope=col>Date</th><th scope=col>HomeTeam</th><th scope=col>AwayTeam</th><th scope=col>FTHG</th><th scope=col>FTAG</th><th scope=col>FTR</th><th scope=col>HTHG</th><th scope=col>HTAG</th><th scope=col>HTR</th><th scope=col>⋯</th><th scope=col>BbAv&lt;2.5</th><th scope=col>BbAH</th><th scope=col>BbAHh</th><th scope=col>BbMxAHH</th><th scope=col>BbAvAHH</th><th scope=col>BbMxAHA</th><th scope=col>BbAvAHA</th><th scope=col>PSCH</th><th scope=col>PSCD</th><th scope=col>PSCA</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>E0</td><td>10/08/2018</td><td>Man United </td><td>Leicester     </td><td>2</td><td>1</td><td>H</td><td>1</td><td>0</td><td>H</td><td>⋯</td><td>1.79</td><td>17</td><td>-0.75</td><td>1.75</td><td>1.70</td><td>2.29</td><td>2.21</td><td>1.55</td><td>4.07</td><td>7.69</td></tr>\n",
       "\t<tr><td>E0</td><td>11/08/2018</td><td>Bournemouth</td><td>Cardiff       </td><td>2</td><td>0</td><td>H</td><td>1</td><td>0</td><td>H</td><td>⋯</td><td>1.83</td><td>20</td><td>-0.75</td><td>2.20</td><td>2.13</td><td>1.80</td><td>1.75</td><td>1.88</td><td>3.61</td><td>4.70</td></tr>\n",
       "\t<tr><td>E0</td><td>11/08/2018</td><td>Fulham     </td><td>Crystal Palace</td><td>0</td><td>2</td><td>A</td><td>0</td><td>1</td><td>A</td><td>⋯</td><td>1.87</td><td>22</td><td>-0.25</td><td>2.18</td><td>2.11</td><td>1.81</td><td>1.77</td><td>2.62</td><td>3.38</td><td>2.90</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>E0</td><td>12/05/2019</td><td>Southampton</td><td>Huddersfield</td><td>1</td><td>1</td><td>D</td><td>1</td><td>0</td><td>H</td><td>⋯</td><td>2.29</td><td>22</td><td>-1.5</td><td>2.27</td><td>2.16</td><td>1.80</td><td>1.73</td><td>1.37</td><td>5.36</td><td>8.49</td></tr>\n",
       "\t<tr><td>E0</td><td>12/05/2019</td><td>Tottenham  </td><td>Everton     </td><td>2</td><td>2</td><td>D</td><td>1</td><td>0</td><td>H</td><td>⋯</td><td>2.07</td><td>19</td><td>-0.5</td><td>2.13</td><td>2.08</td><td>1.85</td><td>1.80</td><td>1.91</td><td>3.81</td><td>4.15</td></tr>\n",
       "\t<tr><td>E0</td><td>12/05/2019</td><td>Watford    </td><td>West Ham    </td><td>1</td><td>4</td><td>A</td><td>0</td><td>2</td><td>A</td><td>⋯</td><td>2.44</td><td>19</td><td>-0.5</td><td>2.25</td><td>2.19</td><td>1.78</td><td>1.72</td><td>2.11</td><td>3.86</td><td>3.41</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 380 × 62\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " Div & Date & HomeTeam & AwayTeam & FTHG & FTAG & FTR & HTHG & HTAG & HTR & ⋯ & BbAv<2.5 & BbAH & BbAHh & BbMxAHH & BbAvAHH & BbMxAHA & BbAvAHA & PSCH & PSCD & PSCA\\\\\n",
       " <chr> & <chr> & <fct> & <fct> & <int> & <int> & <fct> & <dbl> & <dbl> & <chr> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t E0 & 10/08/2018 & Man United  & Leicester      & 2 & 1 & H & 1 & 0 & H & ⋯ & 1.79 & 17 & -0.75 & 1.75 & 1.70 & 2.29 & 2.21 & 1.55 & 4.07 & 7.69\\\\\n",
       "\t E0 & 11/08/2018 & Bournemouth & Cardiff        & 2 & 0 & H & 1 & 0 & H & ⋯ & 1.83 & 20 & -0.75 & 2.20 & 2.13 & 1.80 & 1.75 & 1.88 & 3.61 & 4.70\\\\\n",
       "\t E0 & 11/08/2018 & Fulham      & Crystal Palace & 0 & 2 & A & 0 & 1 & A & ⋯ & 1.87 & 22 & -0.25 & 2.18 & 2.11 & 1.81 & 1.77 & 2.62 & 3.38 & 2.90\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t E0 & 12/05/2019 & Southampton & Huddersfield & 1 & 1 & D & 1 & 0 & H & ⋯ & 2.29 & 22 & -1.5 & 2.27 & 2.16 & 1.80 & 1.73 & 1.37 & 5.36 & 8.49\\\\\n",
       "\t E0 & 12/05/2019 & Tottenham   & Everton      & 2 & 2 & D & 1 & 0 & H & ⋯ & 2.07 & 19 & -0.5 & 2.13 & 2.08 & 1.85 & 1.80 & 1.91 & 3.81 & 4.15\\\\\n",
       "\t E0 & 12/05/2019 & Watford     & West Ham     & 1 & 4 & A & 0 & 2 & A & ⋯ & 2.44 & 19 & -0.5 & 2.25 & 2.19 & 1.78 & 1.72 & 2.11 & 3.86 & 3.41\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 380 × 62\n",
       "\n",
       "| Div &lt;chr&gt; | Date &lt;chr&gt; | HomeTeam &lt;fct&gt; | AwayTeam &lt;fct&gt; | FTHG &lt;int&gt; | FTAG &lt;int&gt; | FTR &lt;fct&gt; | HTHG &lt;dbl&gt; | HTAG &lt;dbl&gt; | HTR &lt;chr&gt; | ⋯ ⋯ | BbAv&lt;2.5 &lt;dbl&gt; | BbAH &lt;dbl&gt; | BbAHh &lt;dbl&gt; | BbMxAHH &lt;dbl&gt; | BbAvAHH &lt;dbl&gt; | BbMxAHA &lt;dbl&gt; | BbAvAHA &lt;dbl&gt; | PSCH &lt;dbl&gt; | PSCD &lt;dbl&gt; | PSCA &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| E0 | 10/08/2018 | Man United  | Leicester      | 2 | 1 | H | 1 | 0 | H | ⋯ | 1.79 | 17 | -0.75 | 1.75 | 1.70 | 2.29 | 2.21 | 1.55 | 4.07 | 7.69 |\n",
       "| E0 | 11/08/2018 | Bournemouth | Cardiff        | 2 | 0 | H | 1 | 0 | H | ⋯ | 1.83 | 20 | -0.75 | 2.20 | 2.13 | 1.80 | 1.75 | 1.88 | 3.61 | 4.70 |\n",
       "| E0 | 11/08/2018 | Fulham      | Crystal Palace | 0 | 2 | A | 0 | 1 | A | ⋯ | 1.87 | 22 | -0.25 | 2.18 | 2.11 | 1.81 | 1.77 | 2.62 | 3.38 | 2.90 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| E0 | 12/05/2019 | Southampton | Huddersfield | 1 | 1 | D | 1 | 0 | H | ⋯ | 2.29 | 22 | -1.5 | 2.27 | 2.16 | 1.80 | 1.73 | 1.37 | 5.36 | 8.49 |\n",
       "| E0 | 12/05/2019 | Tottenham   | Everton      | 2 | 2 | D | 1 | 0 | H | ⋯ | 2.07 | 19 | -0.5 | 2.13 | 2.08 | 1.85 | 1.80 | 1.91 | 3.81 | 4.15 |\n",
       "| E0 | 12/05/2019 | Watford     | West Ham     | 1 | 4 | A | 0 | 2 | A | ⋯ | 2.44 | 19 | -0.5 | 2.25 | 2.19 | 1.78 | 1.72 | 2.11 | 3.86 | 3.41 |\n",
       "\n"
      ],
      "text/plain": [
       "    Div Date       HomeTeam    AwayTeam       FTHG FTAG FTR HTHG HTAG HTR ⋯\n",
       "1   E0  10/08/2018 Man United  Leicester      2    1    H   1    0    H   ⋯\n",
       "2   E0  11/08/2018 Bournemouth Cardiff        2    0    H   1    0    H   ⋯\n",
       "3   E0  11/08/2018 Fulham      Crystal Palace 0    2    A   0    1    A   ⋯\n",
       "⋮   ⋮   ⋮          ⋮           ⋮              ⋮    ⋮    ⋮   ⋮    ⋮    ⋮   ⋱\n",
       "378 E0  12/05/2019 Southampton Huddersfield   1    1    D   1    0    H   ⋯\n",
       "379 E0  12/05/2019 Tottenham   Everton        2    2    D   1    0    H   ⋯\n",
       "380 E0  12/05/2019 Watford     West Ham       1    4    A   0    2    A   ⋯\n",
       "    BbAv<2.5 BbAH BbAHh BbMxAHH BbAvAHH BbMxAHA BbAvAHA PSCH PSCD PSCA\n",
       "1   1.79     17   -0.75 1.75    1.70    2.29    2.21    1.55 4.07 7.69\n",
       "2   1.83     20   -0.75 2.20    2.13    1.80    1.75    1.88 3.61 4.70\n",
       "3   1.87     22   -0.25 2.18    2.11    1.81    1.77    2.62 3.38 2.90\n",
       "⋮   ⋮        ⋮    ⋮     ⋮       ⋮       ⋮       ⋮       ⋮    ⋮    ⋮   \n",
       "378 2.29     22   -1.5  2.27    2.16    1.80    1.73    1.37 5.36 8.49\n",
       "379 2.07     19   -0.5  2.13    2.08    1.85    1.80    1.91 3.81 4.15\n",
       "380 2.44     19   -0.5  2.25    2.19    1.78    1.72    2.11 3.86 3.41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "match_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create an initial split of data to seperate the training and testing data. We are using a porportion of 75% training data and 25% testing data. The strata is set to FTR (full time results), to get an even split of games where the home team wins and where the home team loses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_split <- initial_split(match_data, prop = 3/4, strata = \"FTR\")   #creating the initial split with the parameters described above\n",
    "match_train <- training(match_split)   #the training data\n",
    "match_test <- testing(match_split)     #the testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a simple visualization to demonstrate what our data represents. Below represents the number of matches won by each home team. We are using the group by and summary functions to see which teams have won the most amount of games and home and the most amount of games away. Note: This visualization is not essential to the regression but demonstrates how the results of our data can be used to create predictions for tables of this sort. Being able to make predictions like this table can guide a person's betting decisions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`summarise()` regrouping output by 'FTR', 'HomeTeam', 'AwayTeam', 'FTHG' (override with `.groups` argument)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_summary_netscore <- match_train %>%   \n",
    "                group_by(FTR, HomeTeam, AwayTeam, FTHG, FTAG) %>%\n",
    "                summarize() %>% \n",
    "                mutate(Net_Score = FTHG - FTAG)  #this subtracts the full time home team goals from the full time away team goals. \n",
    "                                                # this value (NetScore) represents which team wins the game and by how much. For example\n",
    "                                                # if the value is 0, then the game ends in a draw, if the value is positive, then the home team\n",
    "                                                # scored more goals, meaning that the home team won and if the value is negative, then the away\n",
    "                                                # team won by the amount given as NetScore. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A grouped_df: 286 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>FTR</th><th scope=col>HomeTeam</th><th scope=col>AwayTeam</th><th scope=col>FTHG</th><th scope=col>FTAG</th><th scope=col>Net_Score</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>H</td><td>Man United</td><td>Brighton</td><td>2</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>H</td><td>Man United</td><td>Everton </td><td>2</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>H</td><td>Man United</td><td>West Ham</td><td>2</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>D</td><td>Crystal Palace</td><td>Everton  </td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>D</td><td>Crystal Palace</td><td>West Ham </td><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>D</td><td>Crystal Palace</td><td>Newcastle</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A grouped\\_df: 286 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " FTR & HomeTeam & AwayTeam & FTHG & FTAG & Net\\_Score\\\\\n",
       " <fct> & <fct> & <fct> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t H & Man United & Brighton & 2 & 1 & 1\\\\\n",
       "\t H & Man United & Everton  & 2 & 1 & 1\\\\\n",
       "\t H & Man United & West Ham & 2 & 1 & 1\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t D & Crystal Palace & Everton   & 0 & 0 & 0\\\\\n",
       "\t D & Crystal Palace & West Ham  & 1 & 1 & 0\\\\\n",
       "\t D & Crystal Palace & Newcastle & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A grouped_df: 286 × 6\n",
       "\n",
       "| FTR &lt;fct&gt; | HomeTeam &lt;fct&gt; | AwayTeam &lt;fct&gt; | FTHG &lt;int&gt; | FTAG &lt;int&gt; | Net_Score &lt;int&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| H | Man United | Brighton | 2 | 1 | 1 |\n",
       "| H | Man United | Everton  | 2 | 1 | 1 |\n",
       "| H | Man United | West Ham | 2 | 1 | 1 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| D | Crystal Palace | Everton   | 0 | 0 | 0 |\n",
       "| D | Crystal Palace | West Ham  | 1 | 1 | 0 |\n",
       "| D | Crystal Palace | Newcastle | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "    FTR HomeTeam       AwayTeam  FTHG FTAG Net_Score\n",
       "1   H   Man United     Brighton  2    1    1        \n",
       "2   H   Man United     Everton   2    1    1        \n",
       "3   H   Man United     West Ham  2    1    1        \n",
       "⋮   ⋮   ⋮              ⋮         ⋮    ⋮    ⋮        \n",
       "284 D   Crystal Palace Everton   0    0    0        \n",
       "285 D   Crystal Palace West Ham  1    1    0        \n",
       "286 D   Crystal Palace Newcastle 0    0    0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_summary_netscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`summarise()` regrouping output by 'FTR' (override with `.groups` argument)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_summary_nwin_home <- match_train %>% \n",
    "                group_by(FTR, HomeTeam) %>%\n",
    "                summarize(TotalWinsHome = n()) %>% \n",
    "                arrange(desc(TotalWinsHome))  #arranging by descending number of wins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'training_summary_nwin_home' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'training_summary_nwin_home' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "training_summary_nwin_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in match_train %>% group_by(FTR, AwayTeam) %>% summarize(TotalWinsAway = n()) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in match_train %>% group_by(FTR, AwayTeam) %>% summarize(TotalWinsAway = n()) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "training_summary_nwin_away <- match_train %>% \n",
    "                group_by(FTR, AwayTeam) %>%\n",
    "                summarize(TotalWinsAway = n()) %>% \n",
    "                arrange(desc(TotalWinsAway))  #arranging by descending number of wins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'training_summary_netscore' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'training_summary_netscore' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "training_summary_netscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan on using a regression model to predict the value of netscore, which will be able to give us our intended results, which are which team wins the game, and by how much.\n",
    "The below visualization in a form of a scatter plot demonstrates how we will take the value of our prediction (NetScore) and extract the final data we want, which includes which team won and by how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in match_train %>% mutate(NetScore = FTHG - FTAG, NetShots = HS - : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in match_train %>% mutate(NetScore = FTHG - FTAG, NetShots = HS - : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "options(repr.plot.height = 8, repr.plot.width = 16)\n",
    "\n",
    "netscore_vs_netshots_plot <- match_train %>% \n",
    "    mutate(NetScore = FTHG - FTAG, NetShots = HS - AS) %>% \n",
    "    ggplot(aes(x= NetShots, y = NetScore, color = FTR)) +\n",
    "    geom_point() +\n",
    "    labs(x= \"Net Shots (Home Shots - Away Shots)\", y = \"Net Goals (Home Goals - Away Goals)\", \n",
    "        color = \"Outcome of Match\") +\n",
    "    ggtitle(\"Net Goals Against Net Shots Per Match in the Premier League (Figure 1)\") +\n",
    "    theme(text = element_text(size=20))\n",
    "\n",
    "netscore_vs_netshots_ongoal_plot <- match_train %>% \n",
    "    mutate(NetScore = FTHG - FTAG, NetShotsOnGoal = HST - AST) %>% \n",
    "    ggplot(aes(x= NetShotsOnGoal, y = NetScore, color = FTR)) +\n",
    "    geom_point() +\n",
    "    labs(x= \"Net Shots on Target (Home Shots on Target - Away Shots on Target)\", \n",
    "         y = \"Net Goals (Home Goals - Away Goals)\",\n",
    "        color = \"Outcome of Match\") +\n",
    "    ggtitle(\"Net Goals Against Net Shots On Goal Per Match in the Premier League (Figure 2)\") +\n",
    "    theme(text = element_text(size=20))\n",
    "\n",
    "\n",
    "netscore_vs_netshots_plot\n",
    "netscore_vs_netshots_ongoal_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that:  H = Home Team Win | D = Draw/Tie | A = Away Team Win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable explanation:\n",
    "We plan on using the following factors to conduct our data analysis:\n",
    "Chosen Variables/Columns| Justification: \n",
    "\n",
    "FTHG and HG = Full Time Home Team Goals\n",
    "Testing Data: Not used in our predictions\n",
    "FTAG and AG = Full Time Away Team Goals\n",
    "Testing Data: Not used in our predictions\n",
    "FTR and Res = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "Testing Data: Not used in our predictions\n",
    "HTHG = Half Time Home Team Goals\n",
    "Allows for performance assessment at half time when paired with total attempted team shots.\n",
    "HTAG = Half Time Away Team Goals\n",
    "\n",
    "\n",
    "HTR = Half Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "\n",
    "\n",
    "HS = Home Team Shots\n",
    "Combined with total team goals, total team shots allow us to further predict the accuracy of the team at halftime.\n",
    "AS = Away Team Shots\n",
    "\n",
    "\n",
    "HST = Home Team Shots on Target\n",
    "(Shot blocked by opponent’s goalie)\n",
    "This factor pair gives us an idea of how many times a team got close to the opponent’s net and the effectiveness of their \n",
    "opponent’s goalie.\n",
    "AST = Away Team Shots on Target\n",
    "(Shot blocked by opponent’s goalie)\n",
    "\n",
    "\n",
    "HHW = Home Team Hit Woodwork\n",
    "Alongside HST and AST, these factors show us how many times a team got within shooting distance of the net.\n",
    "AHW = Away Team Hit Woodwork\n",
    "\n",
    "\n",
    "HC = Home Team Corners\n",
    "Shows a team’s accuracy and how often the team reaches the opponent’s goal.\n",
    "AC = Away Team Corners\n",
    "\n",
    "\n",
    "HFKC = Home Team Free Kicks Conceded\n",
    "\n",
    "\n",
    "AFKC = Away Team Free Kicks Conceded\n",
    "\n",
    "\n",
    "HO = Home Team Offsides\n",
    "Frequency of fouls and how often the team is around the opponent’s goal\n",
    "AO = Away Team Offsides\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outcomes and significance\n",
    "In our data analysis, we expect to successfully and accurately find the winner between two teams, alongside the final score. \n",
    "These findings could increase the probability of an accurate prediction regarding the outcome of a game between two teams. Our \n",
    "analysis can then be used to answer future questions, such as : Which team in a league has the greatest chances of winning for \n",
    "the given season?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Regression Model\n",
    "\n",
    "Below we will create the regression model to predict NetScore using both KNN and linear regression to compare which method leads to a better result with a lower RMPSE. Minor iterations will also be done testing which predictor variables lead to the best reression results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in mutate(match_train, NetScore = FTHG - FTAG): could not find function \"mutate\"\n",
     "output_type": "error",
     "traceback": [
      "Error in mutate(match_train, NetScore = FTHG - FTAG): could not find function \"mutate\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_train <- mutate(match_train, NetScore = FTHG - FTAG) #Creating the NetScore collumns for training data\n",
    "match_test <- mutate(match_test, NetScore = FTHG - FTAG) #Creating the NetScore collumns for testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating KNN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(1234) #setting the seed so the regression predictions are reproducible\n",
    "\n",
    "# using 5 fold cross validation to get multiple subsplits wihtin the training data to choose the best value for k\n",
    "match_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% \n",
    "      set_engine(\"kknn\") %>%\n",
    "      set_mode(\"regression\") \n",
    "\n",
    "# recipe varition 1, that includes less predictors. The predictors in this variable include: home/away team half time goals, home/away shots, \n",
    "# home/away shots on target and we also include existing betting data from other users to pickup trends in the betting odds. collumns B365H:IWA \n",
    "# all consist of the betting odds from various betting websites\n",
    "match_recipe_home_1 <- recipe(NetScore ~ HTHG+HTAG+HS+AS+HST+AST+#HF+AF+HC+AC+HY+AY+HR+AR+\n",
    "                            B365H+B365D+B365A+BWH+BWD+BWA+IWH+IWD+IWA, data = match_train) %>%\n",
    "      step_scale(all_predictors()) %>%\n",
    "      step_center(all_predictors())\n",
    "\n",
    "# recipe variation 2: this one includes all the previous predictors in recipe 1 but add in; home/away fouls, home/away corners\n",
    "match_recipe_home_2 <- recipe(NetScore ~ HTHG+HTAG+HS+AS+HST+AST+HF+AF+HC+AC+#HY+AY+HR+AR+\n",
    "                            B365H+B365D+B365A+BWH+BWD+BWA+IWH+IWD+IWA, data = match_train) %>%\n",
    "      step_scale(all_predictors()) %>%\n",
    "      step_center(all_predictors())\n",
    "\n",
    "# recipe variation 3: this one includes all the previous predictors in recipe 1&2 but add in; home/away yellow cards and home/away red cards\n",
    "match_recipe_home_3 <- recipe(NetScore ~ HTHG+HTAG+HS+AS+HST+AST+HF+AF+HC+AC+#HY+AY+HR+AR+\n",
    "                            B365H+B365D+B365A+BWH+BWD+BWA+IWH+IWD+IWA, data = match_train) %>%\n",
    "      step_scale(all_predictors()) %>%\n",
    "      step_center(all_predictors())\n",
    "\n",
    "#splitting up the training data into 5 cross validation splits so that random variations have less of an impact on the chosen k value\n",
    "match_vfold <- vfold_cv(match_train, v=5, strata = NetScore)\n",
    "\n",
    "#implementing each variation of the recipe into its own workflow so that we can compare which recipe gives the best predictions\n",
    "\n",
    "#uses recipe 1:\n",
    "match_workflow_1 <- workflow() %>% \n",
    "    add_recipe(match_recipe_home_1) %>% \n",
    "    add_model(match_spec)\n",
    "#uses recipe 2:\n",
    "match_workflow_2 <- workflow() %>% \n",
    "    add_recipe(match_recipe_home_2) %>% \n",
    "    add_model(match_spec)\n",
    "#uses recipe 3:\n",
    "match_workflow_3 <- workflow() %>% \n",
    "    add_recipe(match_recipe_home_3) %>% \n",
    "    add_model(match_spec)\n",
    "\n",
    "#making a tibble of possible k values ranging from 1 to 200\n",
    "gridvals <- tibble(neighbors = seq(from = 1, to = 200))\n",
    "\n",
    "# now implemeniting each workflow and collecting metrics in order to compare each recipe\n",
    "match_results_1 <- match_workflow_1 %>% \n",
    "        tune_grid(resamples = match_vfold, grid = gridvals) %>% \n",
    "        collect_metrics()\n",
    "match_results_2 <- match_workflow_2 %>% \n",
    "        tune_grid(resamples = match_vfold, grid = gridvals) %>% \n",
    "        collect_metrics()\n",
    "match_results_3 <- match_workflow_3 %>% \n",
    "        tune_grid(resamples = match_vfold, grid = gridvals) %>% \n",
    "        collect_metrics()\n",
    "\n",
    "#Here we extract the best possible k value from each recipe variation\n",
    "match_min_1 <- match_results_1 %>%\n",
    "   filter(.metric == \"rmse\") %>%\n",
    "   arrange(mean) %>% \n",
    "   slice(1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'match_min_1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'match_min_1' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_min_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in match_results_2 %>% filter(.metric == \"rmse\") %>% arrange(mean) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in match_results_2 %>% filter(.metric == \"rmse\") %>% arrange(mean) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_min_2 <- match_results_2 %>%\n",
    "   filter(.metric == \"rmse\") %>%\n",
    "   arrange(mean) %>% \n",
    "   slice(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'match_min_2' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'match_min_2' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_min_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in match_results_3 %>% filter(.metric == \"rmse\") %>% arrange(mean) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in match_results_3 %>% filter(.metric == \"rmse\") %>% arrange(mean) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_min_3 <- match_results_3 %>%\n",
    "   filter(.metric == \"rmse\") %>%\n",
    "   arrange(mean) %>%\n",
    "slice(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'match_min_3' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'match_min_3' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_min_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe that recipe 1 performs best with 10 neighbours but recipe's 2 and 3 preform best wtih 19 neighbours each. We can also observe that the mean rmse also differes between each recipe. Recipe 1 has the lowest mean rmse with a value of 1.309 compared to that of 1.326 given from recipe 2 and 3. This means that the combination that can give us the best possible predictions has k=10 and uses the predictors from recipe 1. This could be due to the fact that the extra added predictors don't contribute much of significance and only add random noise that skews the predictions. \n",
    "\n",
    "Therefore we will now continue the KNN regression using only match_recipe_home_1 and k=10 neighbours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in match_min_1 %>% pull(neighbors): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in match_min_1 %>% pull(neighbors): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(1234) #keeping the seed the same so that the results are reproducable\n",
    "\n",
    "#using the best recipe combination and the best number of neihgbors (k=10)\n",
    "k_min <- match_min_1 %>%\n",
    "         pull(neighbors)\n",
    "\n",
    "match_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = k_min) %>%\n",
    "         set_engine(\"kknn\") %>%\n",
    "         set_mode(\"regression\")\n",
    "\n",
    "match_best_fit <- workflow() %>%\n",
    "         add_recipe(match_recipe_home_1) %>%\n",
    "         add_model(match_best_spec) %>%\n",
    "         fit(data = match_train)\n",
    "\n",
    "match_summary <- match_best_fit %>%\n",
    "          predict(match_test) %>%\n",
    "          bind_cols(match_test) %>%\n",
    "          metrics(truth = NetScore, estimate = .pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'match_summary' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'match_summary' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "match_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have completed the training and testing of our KNN regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in match_best_fit %>% predict(match_test) %>% bind_cols(match_test) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in match_best_fit %>% predict(match_test) %>% bind_cols(match_test) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "options(repr.plot.width = 7, repr.plot.height = 7) #here we set options for the graph to make a good visualization\n",
    "\n",
    "#here we bind the collumns of the predictions to the actual values\n",
    "match_preds_test <- match_best_fit %>% \n",
    "        predict(match_test) %>% \n",
    "        bind_cols(match_test) %>% \n",
    "        mutate(.pred = as.integer(round(.pred))) %>% \n",
    "        select(.pred, NetScore) %>%   #select only the real values and the predictions\n",
    "        mutate(error = NetScore - .pred)\n",
    "\n",
    "match_preds_train <- match_best_fit %>% \n",
    "        predict(match_train) %>% \n",
    "        bind_cols(match_train) %>% \n",
    "        mutate(.pred = as.integer(round(.pred))) %>% \n",
    "        select(.pred, NetScore) %>%   #select only the real values and the predictions\n",
    "        mutate(error = NetScore - .pred) %>% \n",
    "        glimpse()      #we use the glimpse function to just see a visual numerical comparison between our predictions and the actual values\n",
    "\n",
    "#Because of the high dimensonality of our data, we are unable to make a graph showing our predictions and our results in comparison to our predictors\n",
    "# therefore instead, we plot a histogram to see our error distrubution, where the error is equal to the difference between the predicted value\n",
    "# and the actual value.\n",
    "\n",
    "error_dist_train <- ggplot(match_preds_train, aes(x= error)) + \n",
    "   geom_histogram(binwidth = 1) +\n",
    "   xlab(\"Error Distribution\") +\n",
    "   ylab(\"Count of Prediction Comparisons\") +\n",
    "   ggtitle(\"Training Error Distribution for KNN Regression (figure 3)\")\n",
    "\n",
    "error_dist_test <- ggplot(match_preds_test, aes(x= error)) + \n",
    "   geom_histogram(binwidth = 1) +\n",
    "   xlab(\"Error Distribution\") +\n",
    "   ylab(\"Count of Prediction Comparisons\") +\n",
    "   ggtitle(\"Testing Error Distribution for KNN Regression (figure 4)\")\n",
    "\n",
    "error_dist_test\n",
    "error_dist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we are finally able to visualize how well our model predicts testing data versus using training data. The x-axis of the histogram represents how close the prediction is to the actual value. Thefore a negative x value means that the predictor was too high (NetScore- .pred) and a positive x value means that the model underpredicted the real value. We can see from the histograms that the error in the training data creates a symmetric bell curve but the testing data creates a bell curve that is asymetrical and skewed to the right. This makes sense as obviously our training data would have less error because thats the data it was trained with. \n",
    "\n",
    "From our testing error distribution, we can see that the model tends to underpredict the values of the netscore, but overall it still has a defined peak near x=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in linear_reg() %>% set_engine(\"lm\") %>% set_mode(\"regression\"): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in linear_reg() %>% set_engine(\"lm\") %>% set_mode(\"regression\"): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "#creating a linear spec for linear regression\n",
    "lm_spec <- linear_reg() %>% \n",
    "    set_engine(\"lm\") %>% \n",
    "    set_mode(\"regression\")\n",
    "\n",
    "#creating a fitting using the training data and the best recipe identified earlier.\n",
    "lm_match_fit <- workflow() %>% \n",
    "    add_recipe(match_recipe_home_1) %>%  #using the best recipe pinpointed during the knn regression comparison\n",
    "    add_model(lm_spec) %>% \n",
    "    fit(data = match_train) #fitting the model to the training data\n",
    "\n",
    "#calculating the final rmpse with the testing data and the model\n",
    "lm_match_rmspe <- lm_match_fit %>% \n",
    "    predict(match_test) %>% \n",
    "    bind_cols(match_test) %>% \n",
    "    metrics(truth = NetScore, estimate = .pred) %>% \n",
    "    filter(.metric == \"rmse\") %>% \n",
    "    select(.estimate) %>% \n",
    "    pull()\n",
    "lm_match_rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Linear and KNN Regression\n",
    "When comparing the RMSPE between knn and linear regression, we can observe that (Linear RMPSE = 1.30) and (KNN RMPSE = 1.39). This means that our linear regression model actually predicts the real NetScore better than the knn model!! Therfore our final model should actually be the linear model. This because the linear RMPSE is smaller than the knn RMPSE. \n",
    "\n",
    "Lets create the same kind of histogram we created earlier to see how the error distribution is and if that is visually better as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in lm_match_fit %>% predict(match_test) %>% bind_cols(match_test) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in lm_match_fit %>% predict(match_test) %>% bind_cols(match_test) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#here we bind the collumns of the predictions to the actual values\n",
    "match_preds_test_lm <- lm_match_fit %>% \n",
    "        predict(match_test) %>% \n",
    "        bind_cols(match_test) %>% \n",
    "        mutate(.pred = as.integer(round(.pred))) %>% \n",
    "        select(.pred, NetScore) %>%   #select only the real values and the predictions\n",
    "        mutate(error = NetScore - .pred)\n",
    "\n",
    "match_preds_train_lm <- lm_match_fit %>% \n",
    "        predict(match_train) %>% \n",
    "        bind_cols(match_train) %>% \n",
    "        mutate(.pred = as.integer(round(.pred))) %>% \n",
    "        select(.pred, NetScore) %>%   #select only the real values and the predictions\n",
    "        mutate(error = NetScore - .pred) %>% \n",
    "        glimpse()      #we use the glimpse function to just see a visual numerical comparison between our predictions and the actual values\n",
    "\n",
    "#Because of the high dimensonality of our data, we are unable to make a graph showing our predictions and our results in comparison to our predictors\n",
    "# therefore instead, we plot a histogram to see our error distrubution, where the error is equal to the difference between the predicted value\n",
    "# and the actual value.\n",
    "\n",
    "error_dist_train_lm <- ggplot(match_preds_train_lm, aes(x= error)) + \n",
    "   geom_histogram(binwidth = 1) +\n",
    "   xlab(\"Error Distribution\") +\n",
    "   ylab(\"Count of Prediction Comparisons\") +\n",
    "   ggtitle(\"Training Error Distribution for Linear Regression (figure 5)\")\n",
    "\n",
    "error_dist_test_lm <- ggplot(match_preds_test_lm, aes(x= error)) + \n",
    "   geom_histogram(binwidth = 1) +\n",
    "   xlab(\"Error Distribution\") +\n",
    "   ylab(\"Count of Prediction Comparisons\") +\n",
    "   ggtitle(\"Testing Error Distribution For Linear Regression (figure 6)\")\n",
    "\n",
    "error_dist_test_lm\n",
    "error_dist_train_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets plot the linear and regression error distribution histograms side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'error_dist_test_lm' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'error_dist_test_lm' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "error_dist_test_lm\n",
    "error_dist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our method of analysis, we were able to predict what the score is between two teams after a soccer match by using the process of KNN regression and linear regression. By using both of these methods, we can draw multiple conclusions. What was found when using KNN regression was a mixture of inaccurate and accurate predictions. In the histograms that are titled “Testing Error Distribution for KNN Regression '' and “Training Error Distribution for KNN Regression,” we are able to depict if our predictions are accurate. The x-axis labeled “Error Distribution” represents how close the prediction is to the actual value. A negative value represents that our predicted value is much higher than the actual value and a positive value represents that our model predicted a value that is much lower than the actual value. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By interpreting these KNN histograms, one can see that the distribution is mostly in the x-coordinate, zero. This means the majority of our predictions were correct. The table above these histograms illustrates a comparison between the values we predicted and the actual total score. Under the columns .pred and NetScore there is an integer that identifies the number of goals either the home or away team. The negative integers indicate that the away team and the positive integers indicate that the home team won. By having these results under our .pred column, we were able to make a confident prediction of which team won, while comparing these results to the values under the NetScore column. However, knowing that our results were not as accurate as we wanted, we decided to try using the linear regression method to see if our results would improve. By following similar steps, we produced two histograms again (“Testing Error Distribution for Linear Regression'' and “Training Error Distribution for Linear Regression''). Again we saw that the data on the was histogram mostly distributed towards the x-coordinate zero. This then allowed us to infer that the linear regression method does work well for our dataset. We then compared the RMSPE (root mean prediction square error) to see which model produces more error. With the KNN regression model having an RMSPE value of 1.39 and the linear regression model having one of 1.30, we concluded that the linear regression model had less possibility of error making that model more accurate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our predictions with both models did not one-hundred percent match the actual results that were taken from the dataset, but this was expected due to reasons beyond our control. This is primarily due to the fact that we cannot determine how a player plays because of so many outside influences that may have an impact. These potential influences could vary anywhere from a player’s personal life to the weather, but it is unknown to us. Even with our outlying predictions, this prediction method could open so many new doors within the sporting community. That means that soccer is not the only sport that this method could work for. Our regression method could be used for football, basketball, and other sports that utilize these similar tactics and rules. The only difference would be the predictors one uses to make a prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the world of sports, being able to use a regression algorithm to predict sports outcomes can and does lead to a plethora of questions that have a great impact on the sporting world. It also raises follow-up questions specific to the game of soccer, such as: “Why does the number of corner kicks correspond to more goals and how can my team play to increase the number of corner kicks and goals?”, “How does my team committing a foul on the other team decrease our chances of winning?”, or “Is it statistically better to commit a foul to prevent a corner or is it statistically better to allow the corner to happen to minimize the chances of being scored on?” Using statistical backed information on the game of soccer, in addition to taking into account external factors that are not taken into account in the model such as climate and team morale, it would be interesting to further investigate how the coach can create a game plan for the players such that a team has a higher statistically backed chance of winning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English Premier League (football). DataHub. (n.d.). Retrieved April 7, 2022, from https://datahub.io/sports-data/english-premier-league#data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horky, T., & Pelka, P. (2017). Data Visualisation in Sports Journalism. Digital Journalism, 5(5), 587–606. https://doi.org/10.1080/21670811.2016.1254053 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link, D. (2018). Data Analytics in Professional Soccer. Springer Vieweg, Wiesbaden, 1–136. https://doi.org/10.1007/978-3-658-21177-6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rue, H., & Salvesen, O. (2000). Prediction and retrospective analysis of soccer matches in a league. Journal of the Royal Statistical Society: Series D (The Statistician), 49(3), 399–418. https://doi.org/10.1111/1467-9884.00243 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8 most popular sports to bet on in the world. Pledge Sports. (2022, March 31). Retrieved April 7, 2022, from https://www.pledgesports.org/2020/05/most-popular-sports-to-bet-on/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
